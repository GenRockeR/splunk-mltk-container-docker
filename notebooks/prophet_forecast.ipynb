{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Toolkit for Splunk - Forecasting with Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an example how to use Prophet library for forecasting with the Deep Learning Toolkit for Splunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: By default every time you save this notebook the cells are exported into a python module which is then invoked by Splunk MLTK commands like <code> | fit ... | apply ... | summary </code>. Please read the Model Development Guide in the Deep Learning Toolkit app for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fbprophet import Prophet\n",
    "# ...\n",
    "# global constants\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.18.1\n",
      "pandas version: 1.0.1\n",
      "Prophet: <class 'fbprophet.forecaster.Prophet'>\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)\n",
    "print(\"Prophet: \" + str(Prophet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk\n",
    "In Splunk run a search to pipe a dataset into your notebook environment. Note: mode=stage is used in the | fit command to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| inputlookup bluetooth.csv</br>\n",
    "| where probe=\"AxisBoard-5\" </br>\n",
    "| timechart dc(address) as distinct_addresses span=1h </br>\n",
    "| eval ds=strftime(_time, \"%Y-%m-%d\"), y=distinct_addresses </br>\n",
    "| fit MLTKContainer mode=stage algo=prophet_forecast y from ds into app:prophet_forecast </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run this search your data set sample is available as a csv inside the container to develop your model. The name is taken from the into keyword (\"barebone_model\" in the example above) or set to \"default\" if no into keyword is present. This step is intended to work with a subset of your data to create your custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       ds  y\n",
      "0     2006-01-11 21:00:00  5\n",
      "1     2006-01-11 22:00:00  8\n",
      "2     2006-01-11 23:00:00  7\n",
      "3     2006-01-12 00:00:00  6\n",
      "4     2006-01-12 01:00:00  2\n",
      "...                   ... ..\n",
      "2479  2006-04-30 19:00:00  0\n",
      "2480  2006-04-30 20:00:00  0\n",
      "2481  2006-04-30 21:00:00  0\n",
      "2482  2006-04-30 22:00:00  0\n",
      "2483  2006-04-30 23:00:00  0\n",
      "\n",
      "[2484 rows x 2 columns]\n",
      "{'options': {'params': {'mode': 'stage', 'algo': 'prophet_forecast', 'fit_range_start': '0', 'fit_range_end': '1981'}, 'args': ['y', 'ds'], 'target_variable': ['y'], 'feature_variables': ['ds'], 'model_name': 'prophet_forecast', 'algo_name': 'MLTKContainer', 'mlspl_limits': {'disabled': False, 'handle_new_cat': 'default', 'max_distinct_cat_values': '1000', 'max_distinct_cat_values_for_classifiers': '1000', 'max_distinct_cat_values_for_scoring': '1000', 'max_fit_time': '6000', 'max_inputs': '100000000', 'max_memory_usage_mb': '4000', 'max_model_size_mb': '150', 'max_score_time': '6000', 'streaming_apply': '0', 'use_sampling': '1'}, 'kfold_cv': None}, 'feature_variables': ['ds'], 'target_variables': ['y']}\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "df, param = stage(\"prophet_forecast\")\n",
    "print(df)\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "# initialize your model\n",
    "# available inputs: data and parameters\n",
    "# returns the model object which will be used as a reference to call fit, apply and summary subsequently\n",
    "def init(df,param):\n",
    "    #X = df[param['feature_variables']]\n",
    "    #Y = df[param['target_variables']]\n",
    "    model = Prophet()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "model = init(df,param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "# train your model\n",
    "# returns a fit info json object and may modify the model object\n",
    "def fit(model,df,param):\n",
    "    fit_range_start = int(param['options']['params']['fit_range_start'].lstrip(\"\\\"\").rstrip(\"\\\"\"))\n",
    "    fit_range_end = int(param['options']['params']['fit_range_end'].lstrip(\"\\\"\").rstrip(\"\\\"\"))\n",
    "    df_fit = df[fit_range_start:fit_range_end]\n",
    "    model.fit(df_fit)\n",
    "    info = {\"message\": \"model trained on range \" + str(fit_range_start)+\":\"+str(fit_range_end) }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'model trained on range 0:1981'}\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(fit(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "# apply your model\n",
    "# returns the calculated results\n",
    "def apply(model,df,param):\n",
    "    #future = model.make_future_dataframe(periods=365)\n",
    "    forecast = model.predict(df)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ds     trend  yhat_lower  yhat_upper  trend_lower  \\\n",
      "0    2006-01-11 21:00:00  1.943216    2.987323    7.730210     1.943216   \n",
      "1    2006-01-11 22:00:00  1.942276    2.500524    7.375041     1.942276   \n",
      "2    2006-01-11 23:00:00  1.941337    1.952633    6.871047     1.941337   \n",
      "3    2006-01-12 00:00:00  1.940398    1.914755    6.701869     1.940398   \n",
      "4    2006-01-12 01:00:00  1.939458    1.913381    6.658374     1.939458   \n",
      "...                  ...       ...         ...         ...          ...   \n",
      "2479 2006-04-30 19:00:00  2.379284   -0.060304    4.983714     2.234225   \n",
      "2480 2006-04-30 20:00:00  2.379181    0.825049    5.713774     2.233819   \n",
      "2481 2006-04-30 21:00:00  2.379078    0.971199    5.733541     2.233412   \n",
      "2482 2006-04-30 22:00:00  2.378976    0.473327    5.370917     2.233070   \n",
      "2483 2006-04-30 23:00:00  2.378873    0.041037    4.795607     2.232487   \n",
      "\n",
      "      trend_upper  additive_terms  additive_terms_lower  additive_terms_upper  \\\n",
      "0        1.943216        3.425353              3.425353              3.425353   \n",
      "1        1.942276        2.977971              2.977971              2.977971   \n",
      "2        1.941337        2.479863              2.479863              2.479863   \n",
      "3        1.940398        2.242114              2.242114              2.242114   \n",
      "4        1.939458        2.279645              2.279645              2.279645   \n",
      "...           ...             ...                   ...                   ...   \n",
      "2479     2.526396        0.129358              0.129358              0.129358   \n",
      "2480     2.527019        0.848729              0.848729              0.848729   \n",
      "2481     2.527451        0.897032              0.897032              0.897032   \n",
      "2482     2.527959        0.490544              0.490544              0.490544   \n",
      "2483     2.528312        0.040108              0.040108              0.040108   \n",
      "\n",
      "         daily  daily_lower  daily_upper    weekly  weekly_lower  \\\n",
      "0     2.721609     2.721609     2.721609  0.703745      0.703745   \n",
      "1     2.262151     2.262151     2.262151  0.715820      0.715820   \n",
      "2     1.752191     1.752191     1.752191  0.727672      0.727672   \n",
      "3     1.502974     1.502974     1.502974  0.739139      0.739139   \n",
      "4     1.529572     1.529572     1.529572  0.750072      0.750072   \n",
      "...        ...          ...          ...       ...           ...   \n",
      "2479  2.038965     2.038965     2.038965 -1.909608     -1.909608   \n",
      "2480  2.719398     2.719398     2.719398 -1.870669     -1.870669   \n",
      "2481  2.721609     2.721609     2.721609 -1.824577     -1.824577   \n",
      "2482  2.262151     2.262151     2.262151 -1.771607     -1.771607   \n",
      "2483  1.752191     1.752191     1.752191 -1.712083     -1.712083   \n",
      "\n",
      "      weekly_upper  multiplicative_terms  multiplicative_terms_lower  \\\n",
      "0         0.703745                   0.0                         0.0   \n",
      "1         0.715820                   0.0                         0.0   \n",
      "2         0.727672                   0.0                         0.0   \n",
      "3         0.739139                   0.0                         0.0   \n",
      "4         0.750072                   0.0                         0.0   \n",
      "...            ...                   ...                         ...   \n",
      "2479     -1.909608                   0.0                         0.0   \n",
      "2480     -1.870669                   0.0                         0.0   \n",
      "2481     -1.824577                   0.0                         0.0   \n",
      "2482     -1.771607                   0.0                         0.0   \n",
      "2483     -1.712083                   0.0                         0.0   \n",
      "\n",
      "      multiplicative_terms_upper      yhat  \n",
      "0                            0.0  5.368569  \n",
      "1                            0.0  4.920247  \n",
      "2                            0.0  4.421200  \n",
      "3                            0.0  4.182512  \n",
      "4                            0.0  4.219103  \n",
      "...                          ...       ...  \n",
      "2479                         0.0  2.508641  \n",
      "2480                         0.0  3.227910  \n",
      "2481                         0.0  3.276111  \n",
      "2482                         0.0  2.869520  \n",
      "2483                         0.0  2.418981  \n",
      "\n",
      "[2484 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(apply(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>\"\n",
    "def save(model,name):\n",
    "    model = {}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>\"\n",
    "def load(name):\n",
    "    model = {}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return a model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"numpy\": np.__version__, \"pandas\": pd.__version__} }\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
